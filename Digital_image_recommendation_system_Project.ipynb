{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYJs8WAzssj4Y9w9mhNYfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rogerio5/Digital-image-recommendation-system-Project/blob/main/Digital_image_recommendation_system_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBpNZO38Hrh5"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# üì¶ IMPORTA√á√ïES E CONFIG\n",
        "# =========================\n",
        "import os, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image as PILImage\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from google.colab import files\n",
        "\n",
        "!pip install ipywidgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "\n",
        "# Caminhos principais\n",
        "IMAGE_DIR = \"/content/imagens\"\n",
        "CACHE_FILE = \"/content/catalogo_cache.npz\"\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # Upload manual do CSV (desativado)"
      ],
      "metadata": {
        "id": "YFb-h3_OIgmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üìÇ UPLOAD DE IMAGENS\n",
        "# =========================\n",
        "uploaded = files.upload()\n",
        "for fname in uploaded.keys():\n",
        "    with open(os.path.join(IMAGE_DIR, fname), 'wb') as f:\n",
        "        f.write(uploaded[fname])\n",
        "print(f\"üì• {len(uploaded)} imagens enviadas.\")"
      ],
      "metadata": {
        "id": "lIuWm5dBIhVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üõ† FUN√á√ïES AUXILIARES\n",
        "# =========================\n",
        "def load_and_preprocess_image(path, size=(224, 224)):\n",
        "    img = PILImage.open(path).convert('RGB')\n",
        "    img = img.resize(size)\n",
        "    return np.array(img) / 255.0\n",
        "\n",
        "# Carrega modelo de extra√ß√£o de features\n",
        "model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
        "encoder = hub.load(model_url)\n",
        "\n",
        "def extract_features(img_array):\n",
        "    img_tensor = tf.convert_to_tensor([img_array], dtype=tf.float32)\n",
        "    features = encoder(img_tensor)\n",
        "    return np.array(features)[0]"
      ],
      "metadata": {
        "id": "wPaY49h-IjuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üíæ CACHE AUTOM√ÅTICO\n",
        "# =========================\n",
        "if os.path.exists(CACHE_FILE):\n",
        "    cache = np.load(CACHE_FILE, allow_pickle=True)\n",
        "    vectors = list(cache['vectors'])\n",
        "    names = list(cache['names'])\n",
        "    print(f\"üîÑ Cache carregado com {len(names)} itens.\")\n",
        "else:\n",
        "    vectors, names = [], []\n",
        "    print(\"üìÇ Nenhum cache encontrado, criando do zero.\")\n",
        "\n",
        "all_images = sorted(os.listdir(IMAGE_DIR))\n",
        "new_images = [img for img in all_images if img not in names]\n",
        "\n",
        "if new_images:\n",
        "    print(f\"‚ûï {len(new_images)} imagens novas encontradas.\")\n",
        "    for img_name in tqdm(new_images):\n",
        "        img_array = load_and_preprocess_image(os.path.join(IMAGE_DIR, img_name))\n",
        "        vec = extract_features(img_array)\n",
        "        vectors.append(vec)\n",
        "        names.append(img_name)\n",
        "    np.savez(CACHE_FILE, vectors=np.array(vectors), names=np.array(names))\n",
        "    print(\"üíæ Cache atualizado.\")\n",
        "else:\n",
        "    print(\"‚úÖ Nenhuma imagem nova.\")\n",
        "\n",
        "df = pd.DataFrame({\"name\": names})\n",
        "images = [load_and_preprocess_image(os.path.join(IMAGE_DIR, n)) for n in df['name']]\n",
        "vectors = np.array(vectors)"
      ],
      "metadata": {
        "id": "gKWNYN8rImqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üóë HIST√ìRICO DE EXCLUS√ïES\n",
        "# =========================\n",
        "deleted_items = []\n",
        "\n",
        "def restore_item(name):\n",
        "    global vectors, df, images, deleted_items\n",
        "    item = next((x for x in deleted_items if x['name'] == name), None)\n",
        "    if item:\n",
        "        idx = min(item['idx'], len(df))\n",
        "        df = pd.concat([df.iloc[:idx], pd.DataFrame({\"name\": [item['name']]}), df.iloc[idx:]]).reset_index(drop=True)\n",
        "        images.insert(idx, item['image'])\n",
        "        vectors = np.insert(vectors, idx, [item['vector']], axis=0)\n",
        "        PILImage.fromarray((item['image'] * 255).astype(np.uint8)).save(os.path.join(IMAGE_DIR, item['name']))\n",
        "        np.savez(CACHE_FILE, vectors=vectors, names=df['name'].values)\n",
        "        deleted_items = [x for x in deleted_items if x['name'] != name]\n",
        "        show_recommendations(idx)\n",
        "\n",
        "def delete_item(idx):\n",
        "    global vectors, df, images, deleted_items\n",
        "    del_name = df.loc[idx, 'name']\n",
        "    deleted_items.append({'idx': idx, 'name': del_name, 'image': images[idx], 'vector': vectors[idx]})\n",
        "    df.drop(idx, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    images.pop(idx)\n",
        "    vectors = np.delete(vectors, idx, axis=0)\n",
        "    img_path = os.path.join(IMAGE_DIR, del_name)\n",
        "    if os.path.exists(img_path):\n",
        "        os.remove(img_path)\n",
        "    np.savez(CACHE_FILE, vectors=vectors, names=df['name'].values)\n",
        "    show_restore_options()\n",
        "\n",
        "def show_restore_options():\n",
        "    if deleted_items:\n",
        "        undo_btn = widgets.Button(description=\"‚Ü©Ô∏è Desfazer √∫ltimo\", button_style='info')\n",
        "        undo_btn.on_click(lambda b: restore_item(deleted_items[-1]['name']))\n",
        "        dropdown = widgets.Dropdown(options=[x['name'] for x in deleted_items], description='Restaurar:')\n",
        "        restore_btn = widgets.Button(description=\"Restaurar selecionado\", button_style='success')\n",
        "        restore_btn.on_click(lambda b: restore_item(dropdown.value))\n",
        "        display(widgets.HBox([undo_btn, dropdown, restore_btn]))"
      ],
      "metadata": {
        "id": "CQjXNTlXIs6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üñº VITRINE INTERATIVA\n",
        "# =========================\n",
        "def image_card_with_delete(img_array, label, idx, on_click_callback):\n",
        "    buf = io.BytesIO()\n",
        "    PILImage.fromarray((img_array * 255).astype(np.uint8)).save(buf, format='PNG')\n",
        "    buf.seek(0)\n",
        "    img_widget = widgets.Image(value=buf.getvalue(), format='png', width=150, height=150)\n",
        "    btn_ref = widgets.Button(description=label, layout=widgets.Layout(width='150px'))\n",
        "    btn_ref.on_click(lambda b: on_click_callback(idx))\n",
        "    btn_del = widgets.Button(description=\"üóëÔ∏è\", layout=widgets.Layout(width='40px'))\n",
        "    btn_del.on_click(lambda b: confirm_delete(idx))\n",
        "    return widgets.VBox([img_widget, btn_ref, btn_del])\n",
        "\n",
        "def confirm_delete(idx):\n",
        "    del_name = df.loc[idx, 'name']\n",
        "    confirm_label = widgets.Label(f\"Tem certeza que deseja excluir '{del_name}'?\")\n",
        "    btn_yes = widgets.Button(description=\"Sim\", button_style='danger')\n",
        "    btn_no = widgets.Button(description=\"N√£o\", button_style='success')\n",
        "    btn_yes.on_click(lambda b: (clear_output(wait=True), delete_item(idx)))\n",
        "    btn_no.on_click(lambda b: (clear_output(wait=True), show_recommendations(idx)))\n",
        "    display(widgets.VBox([confirm_label, widgets.HBox([btn_yes, btn_no])]))\n",
        "\n",
        "def show_recommendations(ref_index, top_k=5):\n",
        "    clear_output(wait=True)\n",
        "    if len(df) == 0:\n",
        "        print(\"üìÇ Cat√°logo vazio.\")\n",
        "        show_restore_options()\n",
        "        return\n",
        "    ref_vector = vectors[ref_index]\n",
        "    similarities = cosine_similarity([ref_vector], vectors)[0]\n",
        "    top_indices = np.argsort(similarities)[::-1][1:top_k+1]\n",
        "    print(f\"Imagem de refer√™ncia: {df['name'][ref_index]}\")\n",
        "    display(image_card_with_delete(images[ref_index], f\"Refer√™ncia\\n(100%)\", ref_index, show_recommendations))\n",
        "    print(\"\\nMais parecidas:\")\n",
        "    buttons = [image_card_with_delete(images[idx], f\"{df['name'][idx]}\\n({similarities[idx]*100:.1f}%)\", idx, show_recommendations) for idx in top_indices]\n",
        "    display(widgets.HBox(buttons))\n",
        "    display(search_box)\n",
        "    show_restore_options()\n",
        "\n",
        "def on_search_change(change):\n",
        "    query = change['new'].strip().lower()\n",
        "    matches = df[df['name'].str.lower().str.contains(query)]\n",
        "    if not matches.empty:\n",
        "        show_recommendations(matches.index[0], top_k=5)\n",
        "\n",
        "search_box = widgets.Text(placeholder='Digite parte do nome...', description='Buscar:', continuous_update=False)\n",
        "search_box.observe(on_search_change, names='value')"
      ],
      "metadata": {
        "id": "gHcOKMEsItlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üöÄ INICIAR SISTEMA\n",
        "# =========================\n",
        "show_recommendations(0, top_k=5)"
      ],
      "metadata": {
        "id": "PtgTPiYxIyis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üîé BUSCA POR CATEGORIA (MESMA CATEGORIA)\n",
        "# =========================\n",
        "def show_recommendations_filtered(ref_index, candidate_indices, top_k=5):\n",
        "    \"\"\"\n",
        "    Mostra 1 refer√™ncia e as 5 mais parecidas, calculadas SOMENTE dentro\n",
        "    do subconjunto candidate_indices (mesma categoria/termo).\n",
        "    \"\"\"\n",
        "    clear_output(wait=True)\n",
        "    if len(candidate_indices) == 0:\n",
        "        print(\"Nenhum candidato encontrado para a categoria.\")\n",
        "        display(search_box)\n",
        "        show_restore_options()\n",
        "        return\n",
        "\n",
        "    # Vetor de refer√™ncia\n",
        "    ref_vector = vectors[ref_index]\n",
        "    # Vetores apenas dos candidatos\n",
        "    cand_vectors = vectors[candidate_indices]\n",
        "    sims = cosine_similarity([ref_vector], cand_vectors)[0]\n",
        "\n",
        "    # Ordena por similaridade dentro do subconjunto e remove o pr√≥prio ref_index\n",
        "    order = np.argsort(sims)[::-1]\n",
        "    ordered_indices = [candidate_indices[i] for i in order if candidate_indices[i] != ref_index]\n",
        "    top_indices = ordered_indices[:top_k]\n",
        "\n",
        "    print(f\"Imagem de refer√™ncia: {df['name'][ref_index]}\")\n",
        "    display(image_card_with_delete(images[ref_index], f\"Refer√™ncia\\n(100%)\", ref_index, lambda idx: show_recommendations_filtered(idx, candidate_indices, top_k)))\n",
        "\n",
        "    print(\"\\nMais 5 parecidas (mesma categoria):\")\n",
        "    buttons = []\n",
        "    for idx in top_indices:\n",
        "        sim_percent = cosine_similarity([ref_vector], [vectors[idx]])[0][0] * 100\n",
        "        buttons.append(image_card_with_delete(images[idx], f\"{df['name'][idx]}\\n({sim_percent:.1f}%)\", idx, lambda i: show_recommendations_filtered(i, candidate_indices, top_k)))\n",
        "\n",
        "    if buttons:\n",
        "        display(widgets.HBox(buttons))\n",
        "    else:\n",
        "        print(\"Sem similares suficientes nessa categoria.\")\n",
        "\n",
        "    display(search_box)\n",
        "    show_restore_options()\n",
        "\n",
        "def on_search_change_same_category(change):\n",
        "    \"\"\"\n",
        "    Busca por termo (ex.: 'relogio', 'sapato', 'blazer', 'perfume', 'jaqueta')\n",
        "    e mostra 1 refer√™ncia + 5 similares dentro do mesmo grupo encontrado.\n",
        "    \"\"\"\n",
        "    query = change['new'].strip().lower()\n",
        "    if not query:\n",
        "        return\n",
        "    matches = df[df['name'].str.lower().str.contains(query)]\n",
        "    if matches.empty:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Nenhum resultado encontrado para: {query}\")\n",
        "        display(search_box)\n",
        "        show_restore_options()\n",
        "        return\n",
        "\n",
        "    # √çndice da refer√™ncia (primeira ocorr√™ncia) e subconjunto candidato\n",
        "    ref_index = matches.index[0]\n",
        "    candidate_indices = matches.index.tolist()\n",
        "    show_recommendations_filtered(ref_index, candidate_indices, top_k=5)\n",
        "\n",
        "# Substitui o handler antigo pelo novo (mesma categoria)\n",
        "try:\n",
        "    search_box.unobserve_all('value')\n",
        "except Exception:\n",
        "    pass\n",
        "search_box.observe(on_search_change_same_category, names='value')\n",
        "\n",
        "print(\"Busca atualizada: refer√™ncia + 5 similares dentro da MESMA categoria digitada.\")"
      ],
      "metadata": {
        "id": "k04oxcr5I1IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üß∞ UTILIDADES\n",
        "# =========================\n",
        "\n",
        "def salvar_cache():\n",
        "    np.savez(CACHE_FILE, vectors=vectors, names=df['name'].values)\n",
        "    print(f\"Cache salvo: {CACHE_FILE}\")\n",
        "\n",
        "def rebuild_from_folder():\n",
        "    \"\"\"\n",
        "    Recalcula TUDO a partir da pasta de imagens (√∫til se o cache corromper ou se trocar o encoder).\n",
        "    \"\"\"\n",
        "    global vectors, names, df, images\n",
        "    file_list = sorted(os.listdir(IMAGE_DIR))\n",
        "    new_vectors, new_names = [], []\n",
        "    for img_name in tqdm(file_list):\n",
        "        img_array = load_and_preprocess_image(os.path.join(IMAGE_DIR, img_name))\n",
        "        vec = extract_features(img_array)\n",
        "        new_vectors.append(vec)\n",
        "        new_names.append(img_name)\n",
        "\n",
        "    vectors = np.array(new_vectors)\n",
        "    names = new_names\n",
        "    df = pd.DataFrame({\"name\": names})\n",
        "    images = [load_and_preprocess_image(os.path.join(IMAGE_DIR, n)) for n in df['name']]\n",
        "    salvar_cache()\n",
        "    print(\"Reconstru√ß√£o conclu√≠da.\")\n",
        "\n",
        "print(\"Utilidades carregadas: salvar_cache(), rebuild_from_folder()\")"
      ],
      "metadata": {
        "id": "UPEDGb1II38O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# üìä BLOCO 12 - MATRIZ DE SIMILARIDADE ENTRE CATEGORIAS\n",
        "# =========================\n",
        "\n",
        "# üîß Atribui√ß√£o autom√°tica de categorias com base no nome do arquivo\n",
        "df['categoria'] = df['name'].apply(lambda x:\n",
        "    'T√™nis' if 'tenis' in x.lower() else\n",
        "    'Perfume' if 'perfume' in x.lower() else\n",
        "    'Jaqueta' if 'jaqueta' in x.lower() else\n",
        "    'Outro'\n",
        ")\n",
        "\n",
        "# üìä Gera√ß√£o da matriz de similaridade entre categorias\n",
        "categorias = df['categoria'].unique()\n",
        "matriz_cat = np.zeros((len(categorias), len(categorias)))\n",
        "\n",
        "for i, cat1 in enumerate(categorias):\n",
        "    for j, cat2 in enumerate(categorias):\n",
        "        idx1 = df[df['categoria'] == cat1].index\n",
        "        idx2 = df[df['categoria'] == cat2].index\n",
        "        matriz_cat[i, j] = cosine_similarity(\n",
        "            vectors[idx1].mean(axis=0).reshape(1, -1),\n",
        "            vectors[idx2].mean(axis=0).reshape(1, -1)\n",
        "        )[0][0]\n",
        "\n",
        "# üé® Visualiza√ß√£o com heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matriz_cat, xticklabels=categorias, yticklabels=categorias, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Similaridade m√©dia entre categorias\")\n",
        "plt.xlabel(\"Categoria Comparada\")\n",
        "plt.ylabel(\"Categoria Base\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6wj9uEs-I6us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üéØ PCA COM FILTRO POR CATEGORIA\n",
        "# =========================\n",
        "\n",
        "def plot_pca_filtrado(vectors, labels, categorias, modo='2D', categoria_selecionada=None):\n",
        "    if categoria_selecionada:\n",
        "        mask = df['categoria'] == categoria_selecionada\n",
        "        vectors = vectors[mask]\n",
        "        labels = df['name'][mask]\n",
        "        categorias = df['categoria'][mask]\n",
        "\n",
        "    if modo == '2D':\n",
        "        pca = PCA(n_components=2)\n",
        "        coords = pca.fit_transform(vectors)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.scatter(coords[:, 0], coords[:, 1], c='skyblue', s=50)\n",
        "        for i, name in enumerate(labels):\n",
        "            plt.text(coords[i, 0], coords[i, 1], name, fontsize=8)\n",
        "\n",
        "        plt.title(f\"Mapa 2D - Categoria: {categoria_selecionada or 'Todas'}\")\n",
        "        plt.xlabel(\"Componente 1\")\n",
        "        plt.ylabel(\"Componente 2\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        pca = PCA(n_components=3)\n",
        "        coords = pca.fit_transform(vectors)\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(coords[:, 0], coords[:, 1], coords[:, 2], c='skyblue', s=50)\n",
        "        for i, name in enumerate(labels):\n",
        "            ax.text(coords[i, 0], coords[i, 1], coords[i, 2], name, fontsize=8)\n",
        "\n",
        "        ax.set_title(f\"Mapa 3D - Categoria: {categoria_selecionada or 'Todas'}\")\n",
        "        ax.set_xlabel(\"Componente 1\")\n",
        "        ax.set_ylabel(\"Componente 2\")\n",
        "        ax.set_zlabel(\"Componente 3\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Widgets de controle\n",
        "modo_pca = widgets.ToggleButtons(\n",
        "    options=['2D', '3D'],\n",
        "    description='Visualiza√ß√£o:',\n",
        "    button_style='info'\n",
        ")\n",
        "\n",
        "categoria_dropdown = widgets.Dropdown(\n",
        "    options=['Todas'] + sorted(df['categoria'].unique()),\n",
        "    description='Categoria:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "def atualizar_visualizacao(change=None):\n",
        "    clear_output(wait=True)\n",
        "    modo = modo_pca.value\n",
        "    categoria = categoria_dropdown.value\n",
        "    cat = None if categoria == 'Todas' else categoria\n",
        "    plot_pca_filtrado(vectors, df['name'], df['categoria'], modo=modo, categoria_selecionada=cat)\n",
        "    display(widgets.HBox([modo_pca, categoria_dropdown]))\n",
        "\n",
        "modo_pca.observe(atualizar_visualizacao, names='value')\n",
        "categoria_dropdown.observe(atualizar_visualizacao, names='value')\n",
        "\n",
        "# Exibe os controles e inicia com visualiza√ß√£o padr√£o\n",
        "atualizar_visualizacao()"
      ],
      "metadata": {
        "id": "0ktijVPQJBWM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}